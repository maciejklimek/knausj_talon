from talon.grammar.dfa_compile import DFARule, builtin_rules
from talon.grammar.dfa import NFA
from talon.grammar import Grammar, Rule
import json

if True:
    with open('grammar-fidget1.json', 'r') as f:
        data = json.load(f)
else:
    from talon import speech_system
    grammar = speech_system.grammar
    data = {
        "rules": {name: (rule[0].rule, rule[0].anchor) for name, rule in grammar.rules.items()},
        "lists": {name: list(words) for name, words in grammar.lists.items()},
    }

rules = data['rules']
lists = data['lists']

def build_main(grammar):
    anchor_start: List[str] = []
    anchor_end:   List[str] = []
    anchor_both:  List[str] = []
    ccr_rules:    List[str] = []

    for name, (rule, _) in grammar.rules.items():
        call = f'<{name}>'
        anchor = rule.anchor
        if not anchor:
            ccr_rules.append(call)
        elif anchor == '^':
            anchor_start.append(call)
        elif anchor == '$':
            anchor_end.append(call)
        elif anchor == '^$':
            anchor_both.append(call)

    start_text = '|'.join(anchor_start)
    end_text   = '|'.join(anchor_end)
    both_text  = '|'.join(anchor_both)
    ccr_text   = '|'.join(ccr_rules)

    main_group: List[str] = []
    if start_text: main_group.append(f'[{start_text}]')
    if ccr_text:   main_group.append(f'({ccr_text})*')
    if end_text:   main_group.append(f'[{end_text}]')
    main = ' '.join(main_group)
    if both_text:
        if main:
            main = f'({both_text} | {main})'
        else:
            main = both_text
    return main

grammar = Grammar('main')
for name, (rule_text, rule_anchor) in rules.items():
    rule_text = rule_text.replace('self.', 'user.')
    rule = Rule(rule_text, None)
    rule.anchor = rule_anchor
    grammar.add_rule(name, rule)
grammar.update_lists(lists)
# main_rule = '({})+'.format('|'.join(f'<{name}>' for name in rules.keys()))
main_rule = build_main(grammar)
grammar.compile(main_rule)

from talon.engines import w2l
from talon import app
from talon import speech_system
import time

def on_ready():
    engine = speech_system.engine.engine
    tokens = engine.tokens()
    word_model = engine.word_model

    dfa_lists = {name: NFA.word_list(*words)
                 for name, words in lists.items()}

    for i in range(5):
        start = time.monotonic()
        try:
            cfg = w2l._compile(grammar, dfa_lists, tokens, word_model, debug=True, native=True)
        except TypeError:
            cfg = w2l._compile(grammar, dfa_lists, tokens, word_model, debug=True)
        elapsed = time.monotonic() - start
        print()

    dfa = w2l.cfg_to_dfa(cfg, tokens)
    # print(dfa.ends)
    
# app.register('ready', on_ready)

def on_ready2():
    for i in range(5):
        dfa_lists = {name: NFA.word_list(*words)
                     for name, words in lists.items()}

        dfa_compile_start = time.monotonic()
        dfa_rules = {}
        for name, (rule, public) in grammar.rules.items():
            dfa_rules[name] = DFARule.compile(rule.root)
        dfa_rules.update(builtin_rules)
        compile_elapsed = (time.monotonic() - dfa_compile_start)

        link_start = time.monotonic()
        main_rule = DFARule.compile(grammar.main_root)
        nfa = NFA.blank()
        # print(dfa_rules, dfa_lists)
        state_map = main_rule.link(nfa, 1, dfa_rules, dfa_lists, set())
        link_elapsed = (time.monotonic() - link_start)

        dfa_start = time.monotonic()
        dfa = nfa.minimize()
        min_elapsed = (time.monotonic() - dfa_start)
        total_elapsed = time.monotonic() - dfa_compile_start
        print(f'total={total_elapsed:.3f}s, rule build={compile_elapsed:.3f}s, rule link={link_elapsed:.3f}s, minimize={min_elapsed:.3f}s')

        # print(state_map)
        # print(dfa.perf)

# app.register('ready', on_ready2)

from talon import Module
mod = Module()
@mod.action_class
class Actions:
    def bench1():
        "description"
        on_ready()
